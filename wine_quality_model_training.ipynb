{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T07:04:04.265765Z",
     "start_time": "2025-05-11T07:04:04.262939Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, classification_report,\n",
    "    mean_squared_error, r2_score\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:04:04.462727Z",
     "start_time": "2025-05-11T07:04:04.335439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Load the wine dataset\n",
    "data = load_wine(as_frame=True)\n",
    "X = data.data\n",
    "y_classification = (data.target == 0).astype(int)  # Binary: class 0 vs others\n",
    "y_regression = data.target  # Original multiclass target as regression value\n",
    "\n",
    "# Split dataset for both tasks\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X, y_classification, test_size=0.3, random_state=42, stratify=y_classification)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.3, random_state=42)\n",
    "\n",
    "# Classification models\n",
    "clf_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"=== Classification Metrics ===\")\n",
    "clf_results = {}\n",
    "for name, model in clf_models.items():\n",
    "    model.fit(X_train_clf, y_train_clf)\n",
    "    y_pred = model.predict(X_test_clf)\n",
    "    \n",
    "    clf_results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test_clf, y_pred),\n",
    "        \"Precision\": precision_score(y_test_clf, y_pred),\n",
    "        \"Recall\": recall_score(y_test_clf, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test_clf, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}\")\n",
    "    print(classification_report(y_test_clf, y_pred))\n",
    "\n",
    "print(\"\\nSummary (Classification):\")\n",
    "print(pd.DataFrame(clf_results).T)\n",
    "\n",
    "# Regression models (same structure, but using regression target)\n",
    "reg_models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"\\n=== Regression Metrics ===\")\n",
    "reg_results = {}\n",
    "for name, model in reg_models.items():\n",
    "    model.fit(X_train_reg, y_train_reg)\n",
    "    y_pred = model.predict(X_test_reg)\n",
    "    \n",
    "    reg_results[name] = {\n",
    "        \"MSE\": mean_squared_error(y_test_reg, y_pred),\n",
    "        \"R2 Score\": r2_score(y_test_reg, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"MSE: {reg_results[name]['MSE']:.3f}\")\n",
    "    print(f\"R2 Score: {reg_results[name]['R2 Score']:.3f}\")\n",
    "\n",
    "print(\"\\nSummary (Regression):\")\n",
    "print(pd.DataFrame(reg_results).T)"
   ],
   "id": "29798c23ed058b2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Metrics ===\n",
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        36\n",
      "           1       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.99      0.97      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n",
      "\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92        36\n",
      "           1       0.93      0.72      0.81        18\n",
      "\n",
      "    accuracy                           0.89        54\n",
      "   macro avg       0.90      0.85      0.87        54\n",
      "weighted avg       0.89      0.89      0.88        54\n",
      "\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95        36\n",
      "           1       0.94      0.83      0.88        18\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.93      0.90      0.91        54\n",
      "weighted avg       0.93      0.93      0.92        54\n",
      "\n",
      "\n",
      "Summary (Classification):\n",
      "                          Accuracy  Precision    Recall  F1 Score\n",
      "Logistic Regression       0.981481   1.000000  0.944444  0.971429\n",
      "SVM                       0.888889   0.928571  0.722222  0.812500\n",
      "Random Forest Classifier  0.925926   0.937500  0.833333  0.882353\n",
      "\n",
      "=== Regression Metrics ===\n",
      "\n",
      "Linear Regression\n",
      "MSE: 0.060\n",
      "R2 Score: 0.901\n",
      "\n",
      "SVR\n",
      "MSE: 0.275\n",
      "R2 Score: 0.544\n",
      "\n",
      "Random Forest Regressor\n",
      "MSE: 0.057\n",
      "R2 Score: 0.905\n",
      "\n",
      "Summary (Regression):\n",
      "                              MSE  R2 Score\n",
      "Linear Regression        0.059786  0.900776\n",
      "SVR                      0.274800  0.543930\n",
      "Random Forest Regressor  0.057239  0.905004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:04:04.468667Z",
     "start_time": "2025-05-11T07:04:04.467403Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c86df84dde1b9481",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
